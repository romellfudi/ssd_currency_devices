{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Peruvian-Detect-Multiple-Bills-SSD_Mobilenet-TFLite.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us4ziRKeQgPx",
        "colab_type": "toc"
      },
      "source": [
        ">[Load Data](#scrollTo=hrEEK53cOrs3)\n",
        "\n",
        ">[Load Model](#scrollTo=TFOfVBL4O2l3)\n",
        "\n",
        ">[Our Environment](#scrollTo=iGAUiT1PRMp9)\n",
        "\n",
        ">[Read Bound and make csv files](#scrollTo=nMoiSfRHRPTE)\n",
        "\n",
        ">[Make TFrecords](#scrollTo=t8eZb1oxPQNG)\n",
        "\n",
        ">[Modify Object Detection](#scrollTo=98K0ZiYcPW42)\n",
        "\n",
        ">[Model Configuration](#scrollTo=OLkKudq_Ph3B)\n",
        "\n",
        ">[Load PreTrain Model](#scrollTo=MuygZUkOPpmc)\n",
        "\n",
        ">[Train Model](#scrollTo=pb_crCW_PvFL)\n",
        "\n",
        ">[Find Last Model Generate](#scrollTo=4hnPxcXMP264)\n",
        "\n",
        ">[Export TF Inference graph](#scrollTo=8ww3PVaYP8v5)\n",
        "\n",
        ">[Test Model](#scrollTo=Wh4pHElTQEFt)\n",
        "\n",
        ">[Zip Model](#scrollTo=0xSvyMW8ce7j)\n",
        "\n",
        ">[Download Model](#scrollTo=MiFY3Z2RQTNW)\n",
        "\n",
        ">[Tensorboard](#scrollTo=bNvoKboOQXWq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrEEK53cOrs3",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo90BMLw86Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf images/\n",
        "token = '9699d33508146d528ebf1e6d186c549ceee70328'\n",
        "!git clone --single-branch --branch master https://romellfudi:{token}@github.com/romellfudi/dataset_currency.git\n",
        "!mv dataset_currency/* .\n",
        "!rm -rf dataset_currency/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFOfVBL4O2l3",
        "colab_type": "text"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpTuK2pKM1vq",
        "colab_type": "code",
        "outputId": "496823ff-9a58-4b83-b9a6-af283ad4d951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 31881, done.\u001b[K\n",
            "remote: Total 31881 (delta 0), reused 0 (delta 0), pack-reused 31881\u001b[K\n",
            "Receiving objects: 100% (31881/31881), 511.15 MiB | 14.01 MiB/s, done.\n",
            "Resolving deltas: 100% (20179/20179), done.\n",
            "Checking out files: 100% (3130/3130), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgBcO8bBOwv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd models/research/;protoc --python_out=. ./object_detection/protos/anchor_generator.proto ./object_detection/protos/argmax_matcher.proto ./object_detection/protos/bipartite_matcher.proto ./object_detection/protos/box_coder.proto ./object_detection/protos/box_predictor.proto ./object_detection/protos/eval.proto ./object_detection/protos/faster_rcnn.proto ./object_detection/protos/faster_rcnn_box_coder.proto ./object_detection/protos/grid_anchor_generator.proto ./object_detection/protos/hyperparams.proto ./object_detection/protos/image_resizer.proto ./object_detection/protos/input_reader.proto ./object_detection/protos/losses.proto ./object_detection/protos/matcher.proto ./object_detection/protos/mean_stddev_box_coder.proto ./object_detection/protos/model.proto ./object_detection/protos/optimizer.proto ./object_detection/protos/pipeline.proto ./object_detection/protos/post_processing.proto ./object_detection/protos/preprocessor.proto ./object_detection/protos/region_similarity_calculator.proto ./object_detection/protos/square_box_coder.proto ./object_detection/protos/ssd.proto ./object_detection/protos/ssd_anchor_generator.proto ./object_detection/protos/string_int_label_map.proto ./object_detection/protos/train.proto ./object_detection/protos/keypoint_box_coder.proto ./object_detection/protos/multiscale_anchor_generator.proto ./object_detection/protos/graph_rewriter.proto ./object_detection/protos/calibration.proto ./object_detection/protos/flexible_grid_anchor_generator.proto"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDHYG85uhZAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python models/research/setup.py build\n",
        "!python models/research/setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGAUiT1PRMp9",
        "colab_type": "text"
      },
      "source": [
        "# Our Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J6iXxwkRKz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"models/research/\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
        "  raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRHSqfvER0vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4wg4vNlR0qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "# MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "# DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# PATH_TO_LABELS = os.path.join('models/research/object_detection','data', 'mscoco_label_map.pbtxt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02DMUKvzR0kP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opener = urllib.request.URLopener()\n",
        "# opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "# tar_file = tarfile.open(MODEL_FILE)\n",
        "# for file in tar_file.getmembers():\n",
        "#   file_name = os.path.basename(file.name)\n",
        "#   if 'frozen_inference_graph.pb' in file_name:\n",
        "#     tar_file.extract(file, os.getcwd())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20txOmqJTB4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# detection_graph = tf.Graph()\n",
        "# with detection_graph.as_default():\n",
        "#   od_graph_def = tf.GraphDef()\n",
        "#   with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "#     serialized_graph = fid.read()\n",
        "#     od_graph_def.ParseFromString(serialized_graph)\n",
        "#     tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kmXQ6OsTBzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMoiSfRHRPTE",
        "colab_type": "text"
      },
      "source": [
        "# Read Bound and make csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "57af585b-7abb-4aaa-f797-148875835117",
        "id": "k79_268YPfGQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Write file xml_to_csv.py {display-mode: \"form\"}\n",
        "%%writefile xml_to_csv.py\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    for folder in ['train','test']:\n",
        "        image_path = os.path.join(os.getcwd(), ('images/' + folder))\n",
        "        xml_df = xml_to_csv(image_path)\n",
        "        xml_df.to_csv(('images/' + folder + '_labels.csv'), index=None)\n",
        "        print('Successfully converted xml to csv.')\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting xml_to_csv.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8eZb1oxPQNG",
        "colab_type": "text"
      },
      "source": [
        "# Make TFrecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmolvNgp3BJ0",
        "colab_type": "code",
        "outputId": "4652b127-0536-4b42-a6a8-96f13eeea0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Write file generate_tfrecord.py {display-mode: \"form\"}\n",
        "%%writefile generate_tfrecord.py\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from models.research.object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('image_dir', '', 'Path to the image directory')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "# TO-DO replace this with label map\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'B10':\n",
        "        return 1\n",
        "    elif row_label == 'B20':\n",
        "        return 2\n",
        "    elif row_label == 'B50':\n",
        "        return 3\n",
        "    elif row_label == 'B100':\n",
        "        return 4\n",
        "    else:\n",
        "        None\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
        "    path = os.path.join(os.getcwd(), FLAGS.image_dir)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the TFRecords: {}'.format(output_path))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting generate_tfrecord.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8j92wRBRO04",
        "colab_type": "code",
        "outputId": "a951b619-187b-476d-ba58-0e117d0886a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!python xml_to_csv.py"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yv__iNlr-kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # !rm -rf images/test/P8120001.JPG\n",
        "# !mv train_labels.csv images/\n",
        "# !mv test_labels.csv images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbfVmMtI-gxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record\n",
        "!python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98K0ZiYcPW42",
        "colab_type": "text"
      },
      "source": [
        "# Modify Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgfCYxTXc6pM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp models/research/object_detection/legacy/train.py models/research/object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhYoP-6QoITo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !wget http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqnWrkGFrldm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !tar -xvzf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLVHe-5DD2p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# val = '{'+','.join([f[9:] for f in list_model ])+'}'\n",
        "# !cp training/{val} {train_folder}/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLkKudq_Ph3B",
        "colab_type": "text"
      },
      "source": [
        "# Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yh-5nwYARC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_folder = \"training\"\n",
        "!rm -rf {train_folder}/\n",
        "!mkdir {train_folder}/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsB0jHcIB92y",
        "colab_type": "code",
        "outputId": "16406662-4eed-4069-d639-6ddb712b186c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Write file training/labelmap.pbtxt {display-mode: \"form\"}\n",
        "%%writefile training/labelmap.pbtxt\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'B10'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'B20'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 3\n",
        "  name: 'B50'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 4\n",
        "  name: 'B100'\n",
        "}\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing training/labelmap.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOSBTqmQv4Sv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "420de176-5f9c-46f7-feb2-06cc6f4de607"
      },
      "source": [
        "#@title Write training/ssd_mobilenet_v2_quantized_300x300_coco.config {display-mode: \"form\"}\n",
        "%%writefile {train_folder}/ssd_mobilenet_v2_quantized_300x300_coco.config\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 4\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 1\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00004\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v2'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00004\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000\n",
        "        iou_threshold: 0.99\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 6\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.004\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "  fine_tune_checkpoint: \"models/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt\"\n",
        "  fine_tune_checkpoint_type:  \"detection\"\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 200000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"train.record\"\n",
        "  }\n",
        "  label_map_path: \"training/labelmap.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  num_examples: 8000\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"test.record\"\n",
        "  }\n",
        "  label_map_path: \"training/labelmap.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}\n",
        "\n",
        "graph_rewriter {\n",
        "  quantization {\n",
        "    delay: 48000\n",
        "    weight_bits: 8\n",
        "    activation_bits: 8\n",
        "  }\n",
        "}"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing training/ssd_mobilenet_v2_quantized_300x300_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3bhe1Idq-Gw",
        "colab_type": "code",
        "outputId": "a8e9d971-7026-44e6-f825-2fb03056efca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Write file models/research/object_detection/train.py {display-mode: \"form\"}\n",
        "%%writefile models/research/object_detection/train.py\n",
        "import functools\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "sys.path.append(\"models/research/\")\n",
        "sys.path.append(\"models/research/slim/\")\n",
        "\n",
        "from object_detection.builders import dataset_builder\n",
        "from object_detection.builders import graph_rewriter_builder\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.legacy import trainer\n",
        "from object_detection.utils import config_util\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')\n",
        "flags.DEFINE_integer('task', 0, 'task id')\n",
        "flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.')\n",
        "flags.DEFINE_boolean('clone_on_cpu', False,\n",
        "                     'Force clones to be deployed on CPU.  Note that even if '\n",
        "                     'set to False (allowing ops to run on gpu), some ops may '\n",
        "                     'still be run on the CPU if they have no GPU kernel.')\n",
        "flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '\n",
        "                     'replicas.')\n",
        "flags.DEFINE_integer('ps_tasks', 0,\n",
        "                     'Number of parameter server tasks. If None, does not use '\n",
        "                     'a parameter server.')\n",
        "flags.DEFINE_string('train_dir', '',\n",
        "                    'Directory to save the checkpoints and training summaries.')\n",
        "\n",
        "flags.DEFINE_string('pipeline_config_path', '',\n",
        "                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
        "                    'file. If provided, other configs are ignored')\n",
        "\n",
        "flags.DEFINE_string('train_config_path', '',\n",
        "                    'Path to a train_pb2.TrainConfig config file.')\n",
        "flags.DEFINE_string('input_config_path', '',\n",
        "                    'Path to an input_reader_pb2.InputReader config file.')\n",
        "flags.DEFINE_string('model_config_path', '',\n",
        "                    'Path to a model_pb2.DetectionModel config file.')\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "@tf.contrib.framework.deprecated(None, 'Use object_detection/model_main.py.')\n",
        "def main(_):\n",
        "  assert FLAGS.train_dir, '`train_dir` is missing.'\n",
        "  if FLAGS.task == 0: tf.gfile.MakeDirs(FLAGS.train_dir)\n",
        "  if FLAGS.pipeline_config_path:\n",
        "    configs = config_util.get_configs_from_pipeline_file(\n",
        "        FLAGS.pipeline_config_path)\n",
        "    if FLAGS.task == 0:\n",
        "      tf.gfile.Copy(FLAGS.pipeline_config_path,\n",
        "                    os.path.join(FLAGS.train_dir, 'pipeline.config'),\n",
        "                    overwrite=True)\n",
        "  else:\n",
        "    configs = config_util.get_configs_from_multiple_files(\n",
        "        model_config_path=FLAGS.model_config_path,\n",
        "        train_config_path=FLAGS.train_config_path,\n",
        "        train_input_config_path=FLAGS.input_config_path)\n",
        "    if FLAGS.task == 0:\n",
        "      for name, config in [('model.config', FLAGS.model_config_path),\n",
        "                           ('train.config', FLAGS.train_config_path),\n",
        "                           ('input.config', FLAGS.input_config_path)]:\n",
        "        tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),\n",
        "                      overwrite=True)\n",
        "\n",
        "  model_config = configs['model']\n",
        "  train_config = configs['train_config']\n",
        "  input_config = configs['train_input_config']\n",
        "\n",
        "  model_fn = functools.partial(\n",
        "      model_builder.build,\n",
        "      model_config=model_config,\n",
        "      is_training=True)\n",
        "\n",
        "  def get_next(config):\n",
        "    return dataset_builder.make_initializable_iterator(\n",
        "        dataset_builder.build(config)).get_next()\n",
        "\n",
        "  create_input_dict_fn = functools.partial(get_next, input_config)\n",
        "\n",
        "  env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
        "  cluster_data = env.get('cluster', None)\n",
        "  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n",
        "  task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n",
        "  task_info = type('TaskSpec', (object,), task_data)\n",
        "\n",
        "  # Parameters for a single worker.\n",
        "  ps_tasks = 0\n",
        "  worker_replicas = 1\n",
        "  worker_job_name = 'lonely_worker'\n",
        "  task = 0\n",
        "  is_chief = True\n",
        "  master = ''\n",
        "\n",
        "  if cluster_data and 'worker' in cluster_data:\n",
        "    # Number of total worker replicas include \"worker\"s and the \"master\".\n",
        "    worker_replicas = len(cluster_data['worker']) + 1\n",
        "  if cluster_data and 'ps' in cluster_data:\n",
        "    ps_tasks = len(cluster_data['ps'])\n",
        "\n",
        "  if worker_replicas > 1 and ps_tasks < 1:\n",
        "    raise ValueError('At least 1 ps task is needed for distributed training.')\n",
        "\n",
        "  if worker_replicas >= 1 and ps_tasks > 0:\n",
        "    # Set up distributed training.\n",
        "    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',\n",
        "                             job_name=task_info.type,\n",
        "                             task_index=task_info.index)\n",
        "    if task_info.type == 'ps':\n",
        "      server.join()\n",
        "      return\n",
        "\n",
        "    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n",
        "    task = task_info.index\n",
        "    is_chief = (task_info.type == 'master')\n",
        "    master = server.target\n",
        "\n",
        "  graph_rewriter_fn = None\n",
        "  if 'graph_rewriter_config' in configs:\n",
        "    graph_rewriter_fn = graph_rewriter_builder.build(\n",
        "        configs['graph_rewriter_config'], is_training=True)\n",
        "\n",
        "  trainer.train(\n",
        "      create_input_dict_fn,\n",
        "      model_fn,\n",
        "      train_config,\n",
        "      master,\n",
        "      task,\n",
        "      FLAGS.num_clones,\n",
        "      worker_replicas,\n",
        "      FLAGS.clone_on_cpu,\n",
        "      ps_tasks,\n",
        "      worker_job_name,\n",
        "      is_chief,\n",
        "      FLAGS.train_dir,\n",
        "      graph_hook_fn=graph_rewriter_fn)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting models/research/object_detection/train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuygZUkOPpmc",
        "colab_type": "text"
      },
      "source": [
        "# Load PreTrain Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMsR7j-IHFxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # copy files\n",
        "# !mv checkpoint training/\n",
        "# !mv pipeline.config training/\n",
        "# !mv graph.pbtxt training/\n",
        "# !mv model.ckpt-* training/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb_crCW_PvFL",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd0b9hZ0RLLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mkdir {train_folder}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQeSFvMTFH8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !python models/research/object_detection/train.py --logtostderr --train_dir={train_folder}/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzs6ygLgRfrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# api_gh = 'https://api.github.com/repos/romellfudi/dataset_currency/releases/'\n",
        "# !curl -s -u romellfudi:{token} {api_gh}tags/RevYolo\n",
        "# # clear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "diCkyUYxDuj-",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !curl -vLJO -H 'Accept: application/octet-stream' -s -u romellfudi:{token} {api_gh}assets/15067164"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI6vizTSTWNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "079bf6a9-43db-4110-fce8-307e86f5531b"
      },
      "source": [
        "# !unzip model_tf_objectDetection.zip -d {train_folder}"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  model_tf_objectDetection.zip\n",
            "  inflating: bills_schedule_2_rates/model.ckpt-59637.index  \n",
            "  inflating: bills_schedule_2_rates/pipeline.config  \n",
            "  inflating: bills_schedule_2_rates/graph.pbtxt  \n",
            "  inflating: bills_schedule_2_rates/model.ckpt-59637.meta  \n",
            "  inflating: bills_schedule_2_rates/checkpoint  \n",
            "  inflating: bills_schedule_2_rates/model.ckpt-59637.data-00000-of-00001  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooT7jc9kkVGs",
        "colab_type": "text"
      },
      "source": [
        "# Train Again?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmivv6B6pfjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz2KiW4Npj5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!tar -xvzf ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EesCqscBp1u2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/ models/research/object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NaJnbH4kUAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python models/research/object_detection/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_quantized_300x300_coco.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hnPxcXMP264",
        "colab_type": "text"
      },
      "source": [
        "# Find Last Model Generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPEjDUduLzfc",
        "colab_type": "code",
        "outputId": "b6cbf51b-37cd-4d5a-e019-f020ad318e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_model = !ls {train_folder}/model.ckpt-*.index -1t\n",
        "best_model = best_model[0][:-6]\n",
        "best_model=best_model.replace(' ','\\ ')\n",
        "best_model"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training/model.ckpt-2471'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xSvyMW8ce7j",
        "colab_type": "text"
      },
      "source": [
        "# Zip Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bimk_FvOYFqr",
        "colab_type": "code",
        "outputId": "609c5224-f034-4660-bcda-38e6dffda60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from pprint import pprint\n",
        "best_model_id = !ls {train_folder}/model.ckpt-*.index -1t\n",
        "best_model_id = best_model_id[0]\n",
        "best_model_id = best_model_id[best_model_id.rfind('-')+1:best_model_id.rfind('.')]\n",
        "print(best_model_id)\n",
        "list_model = !ls  {train_folder}/model.ckpt-{best_model_id}* -1\n",
        "list_model.extend([os.path.join(train_folder,'checkpoint'),\n",
        "                   os.path.join(train_folder,'graph.pbtxt'),\n",
        "                   os.path.join(train_folder,'pipeline.config')])\n",
        "pprint(list_model)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2471\n",
            "['training/model.ckpt-2471.data-00000-of-00001',\n",
            " 'training/model.ckpt-2471.index',\n",
            " 'training/model.ckpt-2471.meta',\n",
            " 'training/checkpoint',\n",
            " 'training/graph.pbtxt',\n",
            " 'training/pipeline.config']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahiU0pcEMO7j",
        "colab_type": "code",
        "outputId": "3843f42f-3365-418f-f107-a5459d420a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import datetime\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "zip_name = 'bills_model_ssd_mobilenet_{}_{}.zip'.format(best_model_id,now.strftime(\"%Y-%m-%d_%H:%M\"))\n",
        "!zip {zip_name} {' '.join(list_model)}\n",
        "print(\"Success in %s Created\" % zip_name)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: training/model.ckpt-2471.data-00000-of-00001 (deflated 7%)\n",
            "  adding: training/model.ckpt-2471.index (deflated 73%)\n",
            "  adding: training/model.ckpt-2471.meta (deflated 94%)\n",
            "  adding: training/checkpoint (deflated 73%)\n",
            "  adding: training/graph.pbtxt (deflated 97%)\n",
            "  adding: training/pipeline.config (deflated 67%)\n",
            "Success in bills_model_ssd_mobilenet_2471_2019-10-27_20:47.zip Created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiFY3Z2RQTNW",
        "colab_type": "text"
      },
      "source": [
        "# Download Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2DeO6HAl2rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(zip_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki-bMiHsVan6",
        "colab_type": "text"
      },
      "source": [
        "# TFLite_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YYEB-WLfYrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceb1951e-b7fa-4de9-bdbd-22192e39d56a"
      },
      "source": [
        "#@title Write file writefile export_tflite_ssd_graph.py {display-mode: \"form\"}\n",
        "%%writefile export_tflite_ssd_graph.py\n",
        "# %%writefile models/research/object_detection/export_tflite_ssd_graph.py\n",
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "import sys\n",
        "sys.path.append(\"models/research/\")\n",
        "sys.path.append(\"models/research/slim/\")\n",
        "from object_detection import export_tflite_ssd_graph_lib\n",
        "from object_detection.protos import pipeline_pb2\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('output_directory', None, 'Path to write outputs.')\n",
        "flags.DEFINE_string(\n",
        "    'pipeline_config_path', None,\n",
        "    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
        "    'file.')\n",
        "flags.DEFINE_string('trained_checkpoint_prefix', None, 'Checkpoint prefix.')\n",
        "flags.DEFINE_integer('max_detections', 10,\n",
        "                     'Maximum number of detections (boxes) to show.')\n",
        "flags.DEFINE_integer('max_classes_per_detection', 1,\n",
        "                     'Maximum number of classes to output per detection box.')\n",
        "flags.DEFINE_integer(\n",
        "    'detections_per_class', 100,\n",
        "    'Number of anchors used per class in Regular Non-Max-Suppression.')\n",
        "flags.DEFINE_bool('add_postprocessing_op', True,\n",
        "                  'Add TFLite custom op for postprocessing to the graph.')\n",
        "flags.DEFINE_bool(\n",
        "    'use_regular_nms', False,\n",
        "    'Flag to set postprocessing op to use Regular NMS instead of Fast NMS.')\n",
        "flags.DEFINE_string(\n",
        "    'config_override', '', 'pipeline_pb2.TrainEvalPipelineConfig '\n",
        "    'text proto to override pipeline_config_path.')\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def main(argv):\n",
        "  del argv  # Unused.\n",
        "  flags.mark_flag_as_required('output_directory')\n",
        "  flags.mark_flag_as_required('pipeline_config_path')\n",
        "  flags.mark_flag_as_required('trained_checkpoint_prefix')\n",
        "\n",
        "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "\n",
        "  with tf.gfile.GFile(FLAGS.pipeline_config_path, 'r') as f:\n",
        "    text_format.Merge(f.read(), pipeline_config)\n",
        "  text_format.Merge(FLAGS.config_override, pipeline_config)\n",
        "  export_tflite_ssd_graph_lib.export_tflite_graph(\n",
        "      pipeline_config, FLAGS.trained_checkpoint_prefix, FLAGS.output_directory,\n",
        "      FLAGS.add_postprocessing_op, FLAGS.max_detections,\n",
        "      FLAGS.max_classes_per_detection, use_regular_nms=FLAGS.use_regular_nms)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run(main)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting models/research/object_detection/export_tflite_ssd_graph.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGGXLz7iVcoi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f95ddaa-941b-4281-bd94-5686b0209d2d"
      },
      "source": [
        "!mkdir TFLite_model"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘TFLite_model’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV1K_zQEVn7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CONFIG_FILE='training/ssd_mobilenet_v2_quantized_300x300_coco.config'\n",
        "CHECKPOINT_PATH=best_model\n",
        "OUTPUT_DIR='TFLite_model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWIMjMYnf24h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python models/research/object_detection/export_tflite_ssd_graph.py --pipeline_config_path={CONFIG_FILE} --trained_checkpoint_prefix={CHECKPOINT_PATH} --output_directory={OUTPUT_DIR} --add_postprocessing_op=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ww3PVaYP8v5",
        "colab_type": "text"
      },
      "source": [
        "# Export TF Lit graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DttWTIo1MokV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "55725faa-6437-4c3e-facc-8902348446a7"
      },
      "source": [
        "tflite = zip_name[:-20] + 'tflite.zip'\n",
        "!zip {tflite} {OUTPUT_DIR}/*\n",
        "print(\"Success in %s Created\" % tflite)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: TFLite_model/tflite_graph.pb (deflated 9%)\n",
            "  adding: TFLite_model/tflite_graph.pbtxt (deflated 56%)\n",
            "Success in bills_model_ssd_mobilenet_2471_tflite.zip Created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFMRINOPFobo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# files.download(tflite)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh4pHElTQEFt",
        "colab_type": "text"
      },
      "source": [
        "# Bazel Tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MZBWWt53emG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR='TFLite_model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq4HPLZh32KB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9c67de7c-5f55-4d44-e808-b7d8c7733ded"
      },
      "source": [
        "!unzip bills_model_ssd_mobilenet_2471_tflite.zip  -d ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  bills_model_ssd_mobilenet_2471_tflite.zip\n",
            "  inflating: ./TFLite_model/tflite_graph.pb  \n",
            "  inflating: ./TFLite_model/tflite_graph.pbtxt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajdc_pxERwSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!sudo apt-get install pkg-config zip g++ zlib1g-dev unzip python3\n",
        "# !find .. -name bazel -exec rm -rf {} \\;\n",
        "b_ver = '0.21.0'\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/{b_ver}/bazel-{b_ver}-installer-linux-x86_64.sh # --output-document=bazel.sh\n",
        "!chmod +x ./bazel-{b_ver}-installer-linux-x86_64.sh\n",
        "!./bazel-{b_ver}-installer-linux-x86_64.sh --user"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpbOHbtdHIzK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d50b58c2-c39b-4d50-ae62-9381f42d81c9"
      },
      "source": [
        "# %%capture\n",
        "# !wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh --output-document=conda.sh\n",
        "# !bash ./conda.sh -y\n",
        "!./bazel-{b_ver}-installer-linux-x86_64.sh"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# Release 0.21.0 (2018-12-19)\n",
            "\n",
            "Baseline: cb9b2afbba3f8d3a1db8bf68e65d06f1b36902f5\n",
            "\n",
            "Cherry picks:\n",
            "\n",
            "   + 12b96466ee0d6ab83f7d4cd24be110bb5021281d:\n",
            "     Windows, test wrapper: rename the associated flag\n",
            "   + 7fc967c4d6435de2bb4e34aac00ca2e499f55fca:\n",
            "     Use a fixed thread pool in ByteStreamBuildEventArtifactUploader\n",
            "   + 798b9a989aa793655d29504edb5fb85f3143db84:\n",
            "     Add --build_event_upload_max_threads option\n",
            "   + dbe05df23ccf4c919379e0294e0701fd3f66739c:\n",
            "     Update the version of  skylib bundled in the distfile\n",
            "\n",
            "Incompatible changes:\n",
            "\n",
            "  - The --experimental_stl command line option is removed.\n",
            "  - aquery defaults to human readable output format.\n",
            "\n",
            "New features:\n",
            "\n",
            "  - repository_ctx.download and repository_ctx.download_and_extract\n",
            "    now return a struct.\n",
            "  - Android Databinding v2 can be enabled with\n",
            "    --experimental_android_databinding_v2.\n",
            "\n",
            "Important changes:\n",
            "\n",
            "  - The deprecated and unmaintained Docker rules in\n",
            "    tools/build_defs/docker were removed. Please use\n",
            "    https://github.com/bazelbuild/rules_docker instead.\n",
            "  - The new --upload_query_output_using_bep query/cquery/aquery flag\n",
            "    causes query outputs to be uploaded via BEP.\n",
            "  - New incompatible flag --incompatible_strict_argument_ordering\n",
            "  - --strict_android_deps and --strict_java_deps were renamed to\n",
            "    --experimental_strict_java_deps\n",
            "  - config_settings that select on \"compiler\" value instead of values\n",
            "    = {\"compiler\" : \"x\"} should use flag_values =\n",
            "    {\"@bazel_tools//tools/cpp:compiler\": \"x\"}.\n",
            "  - The new --upload_query_output_using_bep query/cquery/aquery flag\n",
            "    causes query outputs to be uploaded via BEP.\n",
            "  - Turn on --incompatible_disable_sysroot_from_configuration\n",
            "  - We revamped our Android with Bazel tutorial! Check it out\n",
            "    [here](https://docs.bazel.build/versions/master/tutorial/android-a\n",
            "    pp.html).\n",
            "  - --incompatible_disallow_slash_operator is now on by default\n",
            "  - Enable --experimental_check_desugar_deps by default.  This flag\n",
            "    rules out several types of invalid Android builds at compile-time.\n",
            "  - The --max_config_changes_to_show option lists the names of\n",
            "    options which\n",
            "    have changed and thus caused the analysis cache to be dropped.\n",
            "  - The --experimental_strict_action_env option has been renamed to\n",
            "    --incompatible_strict_action_env and is now on by default. This\n",
            "    means Bazel will no longer use the client's PATH and\n",
            "    LD_LIBRARY_PATH environmental variables in the default action\n",
            "    environment. If the old behavior is desired, pass\n",
            "    --action_env=PATH and --action_env=LD_LIBRARY_PATH.\n",
            "    --noincompatible_strict_action_env will also temporarily restore\n",
            "    the old behavior. However, as --action_env is a more general and\n",
            "    explicit way to pass client environmental variables into actions,\n",
            "    --noincompatible_strict_action_env will eventually be deprecated\n",
            "    and removed. See #6648 for more details.\n",
            "  - XCRUNWRAPPER_LABEL has been removed. If you used this value\n",
            "    before, please use @bazel_tools//tools/objc:xcrunwrapper instead.\n",
            "  - --incompatible_static_name_resolution is no unable by default\n",
            "  - We will phase out --genrule_strategy in favor of\n",
            "    --strategy=Genrule=<value> (for genrules) or\n",
            "    --spawn_strategy=<value> (for all actions).\n",
            "  - --incompatible_package_name_is_a_function is now enabled by\n",
            "    default\n",
            "  - Dynamic execution is now available with\n",
            "    --experimental_spawn_strategy. Dynamic execution allows a build\n",
            "    action to run locally and remotely simultaneously, and Bazel\n",
            "    picks the fastest action. This provides the best of both worlds:\n",
            "    faster clean builds than pure local builds, and faster\n",
            "    incremental builds than pure remote builds.\n",
            "  - --incompatible_package_name_is_a_function is now enabled by\n",
            "    default\n",
            "  - New incompatible flag --incompatible_merge_genfiles_directory\n",
            "  - grpc log now logs updateActionResult\n",
            "  - CppConfiguration doesn't do package loading anymore. That means:\n",
            "    * it's no longer needed to have C++ toolchain available when\n",
            "    building non-C++ projects\n",
            "    * bazel will not analyze C++ toolchain when not needed -> speedup\n",
            "    ~2s on bazel startup when C++ rules using hermetic toolchain are\n",
            "    not loaded\n",
            "  - --incompatible_package_name_is_a_fu...\n",
            "\n",
            "This release contains contributions from many people at Google, as well as andy g scott ?, Attila Ol?h, Benjamin Peterson, Clint Harrison, Dave Lee, Ed Schouten, Greg Estren, Gregor Jasny, Jamie Snape, Jerry Marino, Loo Rong Jie, Or Shachar, Sevki Hasirci, William Chargin.\n",
            "\n",
            "## Build informations\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/defd737)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/usr/local/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /usr/local/lib/bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC4-DDenlxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "4e55b4cc-ed6c-41da-8df6-edd484a595ad"
      },
      "source": [
        "# !source /root/.bazel/bin/bazel-complete.bash\n",
        "!source ~/.bashrc\n",
        "!bazel\n",
        "# !/root/.bazel/bin/bazel\n",
        "# !sh ./bazel-{b_ver}-installer-linux-x86_64.sh --user"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\n",
            "INFO: Invocation ID: 66034e7e-78d4-4efa-ba93-009569569458\n",
            "                                                          [bazel release 0.21.0]\n",
            "Usage: bazel <command> <options> ...\n",
            "\n",
            "Available commands:\n",
            "  analyze-profile     Analyzes build profile data.\n",
            "  aquery              Analyzes the given targets and queries the action graph.\n",
            "  build               Builds the specified targets.\n",
            "  canonicalize-flags  Canonicalizes a list of bazel options.\n",
            "  clean               Removes output files and optionally stops the server.\n",
            "  coverage            Generates code coverage report for specified test targets.\n",
            "  cquery              Loads, analyzes, and queries the specified targets w/ configurations.\n",
            "  dump                Dumps the internal state of the bazel server process.\n",
            "  fetch               Fetches external repositories that are prerequisites to the targets.\n",
            "  help                Prints help for commands, or the index.\n",
            "  info                Displays runtime info about the bazel server.\n",
            "  license             Prints the license of this software.\n",
            "  mobile-install      Installs targets to mobile devices.\n",
            "  print_action        Prints the command line args for compiling a file.\n",
            "  query               Executes a dependency graph query.\n",
            "  run                 Runs the specified target.\n",
            "  shutdown            Stops the bazel server.\n",
            "  sync                Syncs all repositories specified in the workspace file\n",
            "  test                Builds and runs the specified test targets.\n",
            "  version             Prints version information for bazel.\n",
            "\n",
            "Getting more help:\n",
            "  bazel help <command>\n",
            "                   Prints help and options for <command>.\n",
            "  bazel help startup_options\n",
            "                   Options for the JVM hosting bazel.\n",
            "  bazel help target-syntax\n",
            "                   Explains the syntax for specifying targets.\n",
            "  bazel help info-keys\n",
            "                   Displays a list of keys used by the info command.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M40TFJIlUvgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!rm -rf tensorflow/\n",
        "!git clone https://github.com/tensorflow/tensorflow.git \n",
        "!cd tensorflow;git checkout r1.13"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0SK5qUmW3i3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a9a1cea-7f6b-4977-d680-3bc1a4caa549"
      },
      "source": [
        "# %reload_ext tensorflow\n",
        "# !export PATH=\"$PATH:$HOME/bin\"\n",
        "# !chown  /.cache/bazel/\n",
        "!python tensorflow/configure.py\n",
        "# !tensorflow/configure"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Running Bazel server needs to be killed, because the startup options are different.\n",
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "\u001b[35mWARNING: \u001b[0m--batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\n",
            "\u001b[32mINFO: \u001b[0mInvocation ID: 9f3afc9c-4d87-44a6-aa9a-db1de5af8dce\n",
            "\u001b[0mYou have bazel 0.21.0 installed.\n",
            "Please specify the location of python. [Default is /usr/bin/python3]: \n",
            "\n",
            "\n",
            "Found possible Python library paths:\n",
            "  /usr/lib/python3/dist-packages\n",
            "  /usr/local/lib/python3.6/dist-packages\n",
            "Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\n",
            "\n",
            "Do you wish to build TensorFlow with XLA JIT support? [Y/n]: \n",
            "XLA JIT support will be enabled for TensorFlow.\n",
            "\n",
            "Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \n",
            "No OpenCL SYCL support will be enabled for TensorFlow.\n",
            "\n",
            "Do you wish to build TensorFlow with ROCm support? [y/N]: \n",
            "No ROCm support will be enabled for TensorFlow.\n",
            "\n",
            "Do you wish to build TensorFlow with CUDA support? [y/N]: \n",
            "No CUDA support will be enabled for TensorFlow.\n",
            "\n",
            "Do you wish to download a fresh release of clang? (Experimental) [y/N]: \n",
            "Clang will not be downloaded.\n",
            "\n",
            "Do you wish to build TensorFlow with MPI support? [y/N]: \n",
            "No MPI support will be enabled for TensorFlow.\n",
            "\n",
            "Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \n",
            "\n",
            "\n",
            "Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: y\n",
            "Searching for NDK and SDK installations.\n",
            "\n",
            "Please specify the home path of the Android NDK to use. [Default is /root/Android/Sdk/ndk-bundle]: \n",
            "\n",
            "\n",
            "The path /root/Android/Sdk/ndk-bundle or its child file \"source.properties\" does not exist.\n",
            "Please specify the home path of the Android NDK to use. [Default is /root/Android/Sdk/ndk-bundle]: \n",
            "\n",
            "\n",
            "The path /root/Android/Sdk/ndk-bundle or its child file \"source.properties\" does not exist.\n",
            "Please specify the home path of the Android NDK to use. [Default is /root/Android/Sdk/ndk-bundle]: \n",
            "\n",
            "\n",
            "The path /root/Android/Sdk/ndk-bundle or its child file \"source.properties\" does not exist.\n",
            "Please specify the home path of the Android NDK to use. [Default is /root/Android/Sdk/ndk-bundle]: n\n",
            "\n",
            "\n",
            "The path n or its child file \"source.properties\" does not exist.\n",
            "Please specify the home path of the Android NDK to use. [Default is /root/Android/Sdk/ndk-bundle]: \n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"tensorflow/configure.py\", line 1701, in <module>\n",
            "    main()\n",
            "  File \"tensorflow/configure.py\", line 1677, in main\n",
            "    create_android_ndk_rule(environ_cp)\n",
            "  File \"tensorflow/configure.py\", line 680, in create_android_ndk_rule\n",
            "    error_msg=('The path %s or its child file \"source.properties\" '\n",
            "  File \"tensorflow/configure.py\", line 645, in prompt_loop_or_load_from_env\n",
            "    default)\n",
            "  File \"tensorflow/configure.py\", line 568, in get_from_env_or_user_or_default\n",
            "    var = get_input(ask_for_var)\n",
            "  File \"tensorflow/configure.py\", line 93, in get_input\n",
            "    answer = input(question)  # pylint: disable=bad-builtin\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFpZj6S_GdPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CPU\n",
        "%%capture\n",
        "!cd tensorflow;bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEJMswTKaAg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU\n",
        "# %%capture\n",
        "# %cd tensorflow/\n",
        "# !bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf_hZ35Stz9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# mobilenet\n",
        "# !cd tensorflow;bazel run --config=opt tensorflow/lite/toco:toco -- --input_file=/content/TFLite_model/tflite_graph.pb --output_file=/content/TFLite_model/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4kKwEliOKP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# non-quantized SSD \n",
        "!cd tensorflow;bazel run --config=opt tensorflow/lite/toco:toco -- --input_file=/content/TFLite_model/tflite_graph.pb --output_file=/content/TFLite_model/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --inference_type=FLOAT --allow_custom_ops "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZM58yK2UtG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4f7730e-7d0c-4f53-9fcc-c69449dce556"
      },
      "source": [
        "%%writefile {OUTPUT_DIR}/labelmap.txt\n",
        "B10\n",
        "B20\n",
        "B50\n",
        "B100\n"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing TFLite_model/labelmap.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evTdW6JpVoJm",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxT7sM3BVpvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_image.py --no-check-certificate\n",
        "# wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_video.py --no-check-certificate\n",
        "# wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_webcam.py --no-check-certificate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IShPb1iyVtOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_image.py --no-check-certificate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5qkElXrWDkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "b4ceb42f-a132-43d0-b80e-699a11982518"
      },
      "source": [
        "!python TFLite_detection_image.py -h"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: TFLite_detection_image.py [-h] --modeldir MODELDIR [--graph GRAPH]\n",
            "                                 [--labels LABELS] [--threshold THRESHOLD]\n",
            "                                 [--image IMAGE] [--imagedir IMAGEDIR]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --modeldir MODELDIR   Folder the .tflite file is located in\n",
            "  --graph GRAPH         Name of the .tflite file, if different than\n",
            "                        detect.tflite\n",
            "  --labels LABELS       Name of the labelmap file, if different than\n",
            "                        labelmap.txt\n",
            "  --threshold THRESHOLD\n",
            "                        Minimum confidence threshold for displaying detected\n",
            "                        objects\n",
            "  --image IMAGE         Name of the single image to perform detection on. To\n",
            "                        run detection on multiple images, use --imagedir\n",
            "  --imagedir IMAGEDIR   Name of the folder containing images to perform\n",
            "                        detection on. Folder must contain only images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H001l2gJWZ3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "0aa74139-e24b-4ca2-a3df-f38bc9d81fa7"
      },
      "source": [
        "!python TFLite_detection_image.py --modeldir=TFLite_model --image=P8120180.jpeg\n",
        "# !pwd"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"TFLite_detection_image.py\", line 90, in <module>\n",
            "    interpreter.allocate_tensors()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter.py\", line 244, in allocate_tensors\n",
            "    return self._interpreter.AllocateTensors()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 106, in AllocateTensors\n",
            "    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\n",
            "RuntimeError: Encountered unresolved custom op: AddV2.Node number 0 (AddV2) failed to prepare.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKcyjfAWZ36o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac43b157-da5e-4c4a-90a1-bd8c9d92cf04"
      },
      "source": [
        "!ls TFLite_model/"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "detect.tflite  labelmap  labelmap.txt  tflite_graph.pb\ttflite_graph.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNvoKboOQXWq",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJOox7fgfRy8",
        "colab_type": "code",
        "outputId": "f6b1db48-4507-4120-87f3-5f8b4394c8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install -q tf-nightly-2.0-preview\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzEuPtPRfTYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir {train_folder}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4_Ul_ZVfmMo",
        "colab_type": "code",
        "outputId": "4e10af40-ad5f-424e-de95-1468abf97f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorboard import notebook\n",
        "notebook.list()"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No known TensorBoard instances running.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLxtfiInftVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notebook.display(port=6006, height=1000) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmw3qvXXqBVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}